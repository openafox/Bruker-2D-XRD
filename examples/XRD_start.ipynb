{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import inspect\n",
    "from openxrd import find_peaks_2d\n",
    "from openxrd import find_peaks_1d\n",
    "from openxrd import fit_single\n",
    "from openxrd import get_fit_all_1d\n",
    "from openxrd import get_fit_all_2d\n",
    "from openxrd import fits_to_csv_multitype\n",
    "from openxrd import fit_data_to_csv\n",
    "from openxrd import BrukerData\n",
    "from openxrd import fit_multipeak\n",
    "from openxrd import fits_to_csv\n",
    "from openxrd import csv_append_col\n",
    "\n",
    "from datasetmetta import get_name_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib.patheffects as path_effects\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import csv\n",
    "from lmfit import models\n",
    "from lmfit import lineshapes\n",
    "\n",
    "\n",
    "def merge_data(files):\n",
    "    # Merge files into 1 for analysis\n",
    "    data_list = []\n",
    "    file_list = []\n",
    "    for i, f in enumerate(sorted(files)):\n",
    "        datafile = str(f)\n",
    "        # Maybe add output that says joined bla\n",
    "        # print(os.path.basename(datafile)[:-11])\n",
    "        if len(data_list) < 1:\n",
    "            data_list.append(BrukerData(datafile))\n",
    "        else:\n",
    "            data = BrukerData(datafile)\n",
    "            diff = data.x[0] - data_list[-1].x[-1]\n",
    "            step = data.rngs[0].metta['step_size']\n",
    "            if (np.array_equal(data_list[-1].y, data.y) and\n",
    "                    step*-2 < diff < 2*step):  # are ys same and xs overlap?\n",
    "                data_list[-1] = data_list[-1] + data\n",
    "            else:\n",
    "                data_list.append(data)\n",
    "        file_list.append(datafile)\n",
    "    return data_list, file_list\n",
    "\n",
    "def colorbar(mappable):\n",
    "    #http://joseph-long.com/writing/colorbars/\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    return fig.colorbar(mappable, cax=cax)\n",
    "\n",
    "def plot_heatmap(data, title=None, mini=5, maxi=1e3, xy=None, plotpeaks=None):\n",
    "    # colors\n",
    "    # https://matplotlib.org/users/colormaps.html\n",
    "    # https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.pcolor.html\n",
    "    axlabels = {'family':               'sans',\n",
    "                'color':                'black',\n",
    "                'weight':               'normal',\n",
    "                'size':                 20,\n",
    "                }\n",
    "    titles = {'family':                 'sans',\n",
    "              'color':                  'black',\n",
    "              'weight':                 'normal',\n",
    "              'size':                   24,\n",
    "              }\n",
    "    labels = {'family':                 'sans',\n",
    "              'fontname':               'DejaVu Sans',\n",
    "              'color':                  '#66ff33',\n",
    "              'weight':                 'normal',\n",
    "              'size':                   14,\n",
    "              'verticalalignment':      'center',\n",
    "              'horizontalalignment':    'right'\n",
    "              }\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontdict=titles)\n",
    "    plot = ax.pcolormesh(data.x, data.y, data.smap, vmin=mini, vmax=maxi,\n",
    "                         cmap='viridis')  # alpha=0.8)\n",
    "    # plt.pcolor(x, y, data, norm=LogNorm(vmin=data.min()+5,\n",
    "    #            vmax=data.max(), cmap='viridis') #alpha=0.8)\n",
    "    ax.set_xlabel('2\\u03b8[\\u00b0]', fontdict=titles)\n",
    "    ax.set_ylabel(u'\\u03A8[\\u00b0]', fontdict=titles)\n",
    "    if xy is not None:\n",
    "        points = ax.plot(xy[:, 1], xy[:, 0], 'ro', markersize=1)\n",
    "    cbar = colorbar(plot)\n",
    "    cbar.set_ticks([0, 1])\n",
    "    cbar.set_ticklabels([\"\", \"\"])\n",
    "    cbar.set_label(\"Intensity [arbitrary units]\", fontdict=titles)\n",
    "    # Set axis tick labels font\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        for prop in axlabels:\n",
    "            getattr(label, 'set_' + prop)(axlabels[prop])\n",
    "    if plotpeaks:\n",
    "        # fastest?\n",
    "        # https://softwarerecs.stackexchange.com/questions/7463/fastest-python-library-to-read-a-csv-file\n",
    "        with open(plotpeaks, 'r') as f:\n",
    "            peaks = csv.reader(row for row in f if not\n",
    "                               row.startswith('#'))\n",
    "            for peak in peaks:\n",
    "                if (data.x.min() < float(peak[0]) < data.x.max() and\n",
    "                        data.y.min() < float(peak[1]) < data.y.max()):\n",
    "                    txt = ax.text(float(peak[0]), float(peak[1]), peak[2],\n",
    "                                  fontdict=labels)\n",
    "                    txt.set_path_effects([path_effects.Stroke(linewidth=1,\n",
    "                                         foreground='black'),\n",
    "                                         path_effects.Normal()])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get data\n",
    "rootf = 'exfiles/'\n",
    "files = [rootf + 'Map-20.raw', rootf + 'Map-50.raw', rootf + 'Map-80.raw']\n",
    "data_list, file_list = merge_data(files)\n",
    "print(len(data_list))\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    # Plot heat maps\n",
    "    if True:\n",
    "        xy_raw = find_peaks_2d(data.smap)\n",
    "        # rescale xy peaks\n",
    "        xy = np.asarray([data.get_real_xy(row[1], row[0])\n",
    "                        for row in xy_raw])\n",
    "        xy = np.roll(xy, 1, axis=1)  # quick fix. need to do properly\n",
    "\n",
    "        mini = data.smap.min()\n",
    "        ## make this base on fit of distribution??\n",
    "        maxi = data.smap.max()*0.005\n",
    "        peakfile = os.path.join(#os.path.dirname(__file__),\n",
    "                                    'BNKT_peaks.csv')\n",
    "        plot_heatmap(data, maxi=maxi)\n",
    "        # plot_heatmap(data, os.path.basename(file_list[i])[:19], maxi=maxi,\n",
    "                     # xy=xy, plotpeaks=peakfile)\n",
    "        plot_heatmap(data, maxi=maxi, plotpeaks=peakfile)\n",
    "\n",
    "    # Do fits of all Automagically and save in CSV\n",
    "    if False:\n",
    "        # fit all 2th lines\n",
    "        out_2th = get_fit_all_2d(data.smap, xy_raw, data.x, data.y,\n",
    "                                 plot=False)\n",
    "        # fit all psi lines\n",
    "        smapT = data.smap.copy().T\n",
    "        xy_raw = np.roll(xy_raw, 1, axis=1)\n",
    "        out_psi = get_fit_all_2d(smapT, xy_raw, data.y, data.x, plot=False)\n",
    "        # create table and write to csv\n",
    "        table = []\n",
    "        for i, row in enumerate(xy):\n",
    "            table.append([row[0], \n",
    "                            row[1], out_2th[i][2], out_psi[i][2]])\n",
    "            with open(datafile[:-11] + '.csv', 'wb') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(table)\n",
    "\n",
    "    # Manually fit a specific ranges\n",
    "    if False:\n",
    "        # insitue data\n",
    "        if True:\n",
    "            pos = []\n",
    "            peaks = []\n",
    "            # if specific to insitue flat measurement\n",
    "            if (data.y[0] < 0 < data.y[-1] and\n",
    "                data.x[0] < 46 < data.x[-1]):\n",
    "                peaks.append('200')\n",
    "                pos.append(data.get_index_xy(46.79, -10))\n",
    "                pos.append(data.get_index_xy(41, 10))\n",
    "                pos.append(data.get_index_xy(53, 0))\n",
    "                \"\"\"\n",
    "                peaks.append('110')\n",
    "                pos.append(data.get_index_xy(32.5, -10))\n",
    "                pos.append(data.get_index_xy(30, 10))\n",
    "                pos.append(data.get_index_xy(34, 0))\n",
    "                peaks.append('Pt111')\n",
    "                pos.append(data.get_index_xy(39.76, -10))\n",
    "                pos.append(data.get_index_xy(35, 10))\n",
    "                pos.append(data.get_index_xy(45, 0))\n",
    "                \"\"\"\n",
    "            # if specific to insitue tilted measurement\n",
    "            elif (data.y[0] < 45 < data.y[-1] and\n",
    "                  data.x[0] < 32 < data.x[-1]):\n",
    "                \"\"\"\n",
    "                peaks.append('110_100')\n",
    "                pos.append(data.get_index_xy(32.56, 30))\n",
    "                pos.append(data.get_index_xy(30, 60))\n",
    "                pos.append(data.get_index_xy(35, 45))\n",
    "                peaks.append('111_100')\n",
    "                pos.append(data.get_index_xy(40.12, 50))\n",
    "                pos.append(data.get_index_xy(38, 60))\n",
    "                pos.append(data.get_index_xy(40.5, 54.74))\n",
    "                #pos.append(data.get_index_xy(35, 60))\n",
    "                #pos.append(data.get_index_xy(45, 54.74))\n",
    "                peaks.append('Pt200_111')\n",
    "                pos.append(data.get_index_xy(46.24, 45))\n",
    "                pos.append(data.get_index_xy(42, 65))\n",
    "                pos.append(data.get_index_xy(50, 54.74))\n",
    "                \"\"\"\n",
    "        # Si\n",
    "        if False:\n",
    "            pos = []\n",
    "            peaks = []\n",
    "            # if specific to insitue flat measurement\n",
    "            peaks.append('Si_400')\n",
    "            pos.append(data.get_index_xy(69.132, -10))\n",
    "            pos.append(data.get_index_xy(68, 10))\n",
    "            pos.append(data.get_index_xy(72, 0))\n",
    "        # full map data\n",
    "        if False:\n",
    "            peakfile = os.path.join(os.path.dirname(__file__),\n",
    "                                    'BNKT_peaks.csv')\n",
    "            ## make peak file auto creat arrays as below\n",
    "            peak = '100'\n",
    "            pos.append(data.get_index_xy(22.93, -10))\n",
    "            pos.append(data.get_index_xy(17, 10))\n",
    "            pos.append(data.get_index_xy(29, 0))\n",
    "            peak = '110'\n",
    "            pos.append(data.get_index_xy(32.56, -10))\n",
    "            pos.append(data.get_index_xy(30, 80))\n",
    "            pos.append(data.get_index_xy(35, 45))\n",
    "\n",
    "        smapT = data.smap.copy().T\n",
    "        lines = []\n",
    "        name = os.path.basename(file_list[i])[:23]\n",
    "        basename = os.path.dirname(file_list[i])\n",
    "        directory = os.path.abspath(os.path.join(basename, os.pardir))\n",
    "        print(basename)\n",
    "        print(name)\n",
    "        for i in range(len(peaks)):\n",
    "            print(peaks[i])\n",
    "            # should we use an integrated area or a slice of the data\n",
    "            integrate = True\n",
    "            # which models to use\n",
    "            # mods = [models.Pearson7Model, models.VoigtModel,\n",
    "            #        models.PseudoVoigtModel]\n",
    "            mods = [models.PseudoVoigtModel]\n",
    "            # Psi\n",
    "            if False:\n",
    "                x = data.y[pos[i*3][1]:pos[i*3+1][1]]\n",
    "                if integrate:\n",
    "                    y = data.integrate_2d([pos[i*3+1][0], pos[i*3][1],\n",
    "                                           pos[i*3+2][0], pos[i*3+1][1]],\n",
    "                                           'y')\n",
    "                else:\n",
    "                    y = smapT[pos[i*3][0], pos[i*3][1]:pos[i*3+1][1]]\n",
    "\n",
    "                # Do fit\n",
    "                savename = os.path.join(directory, '%s_psi' % peaks[i])\n",
    "                if True:\n",
    "                    fits_to_csv_multitype(\n",
    "                                x, y, name, savename,  mods,\n",
    "                                psi=True,\n",
    "                                extrahead=['comp', 'thick', 'num', 'volt'],\n",
    "                                extra=get_name_data(name),\n",
    "                                plot=False, plot_all=False,\n",
    "                                print_out=False)\n",
    "\n",
    "                # Fit data to csv\n",
    "                if False:\n",
    "                    fit_data_to_csv(x, y, name, savename, plot=False)\n",
    "\n",
    "            csvheads = ['name', 'model',  'mid_obs', 'height_obs', 'comp',\n",
    "                        'thick', 'num', 'volt', 'center','center_error',\n",
    "                        '2d', '2d_error', 'height', 'fwhm', 'sigma',\n",
    "                        'amplitude', 'sigma_error', 'amplitude_error',\n",
    "                        'r^2', 'decay', 'slope', 'intercept']\n",
    "            xdata = get_name_data(name)\n",
    "            extradata = {'comp': xdata[0], 'thick': xdata[1],\n",
    "                         'num': xdata[2], 'volt': xdata[3]}\n",
    "            # 2th\n",
    "            if True:\n",
    "                x = data.x[pos[i*3+1][0]:pos[i*3+2][0]]\n",
    "                if integrate:\n",
    "                    y = data.integrate_2d([pos[i*3+1][0], pos[i*3][1],\n",
    "                                           pos[i*3+2][0], pos[i*3+1][1]],\n",
    "                                            'x')\n",
    "                else:\n",
    "                    y = data.smap[pos[i*3+2][1], pos[i*3+1][0]:pos[i*3+2][0]]\n",
    "                # Do Fit\n",
    "                savename = os.path.join(directory, '%s_2th' % peaks[i])\n",
    "                if False:\n",
    "                    fits_to_csv_multitype(\n",
    "                                x, y, name, savename,  mods,\n",
    "                                psi=False,\n",
    "                                extrahead=['comp', 'thick', 'num', 'volt'],\n",
    "                                extra=get_name_data(name),\n",
    "                                plot=True, plot_all=False,\n",
    "                                print_out=False)\n",
    "                # Fit data to csv\n",
    "                if False:\n",
    "                    fit_data_to_csv(x, y, name, savename, plot=False)\n",
    "                # fit as multiple peaks\n",
    "                if True:\n",
    "                # compair these\n",
    "                    out = []\n",
    "                    rsqd = []\n",
    "                    \"\"\"\n",
    "                    print('single')\n",
    "                    out.append(fit_single(x, y, plot=False))\n",
    "                    print('single poly')\n",
    "                    out.append(fit_multipeak(x, y, name,\n",
    "                                     models=[models.PseudoVoigtModel],\n",
    "                                        background_mod=models.PolynomialModel,\n",
    "                                        plot=False))\n",
    "                    \"\"\"\n",
    "                    print('double poly')\n",
    "                    out.append(fit_multipeak(x, y, name,\n",
    "                                         models=[models.PseudoVoigtModel,\n",
    "                                                    models.PseudoVoigtModel],\n",
    "                                        background_mod=models.PolynomialModel,\n",
    "                                          plot=False))\n",
    "                    #fits_to_csv([o for o in out], csvheads,\n",
    "                    #            [extradata, extradata, extradata],\n",
    "                    #            name, savename)\n",
    "                    # Add data to csv\n",
    "                    fn = os.path.join(directory, 'fitdata')\n",
    "                    csv_append_col(fn, [name + '_x'] + x.tolist())\n",
    "                    csv_append_col(fn, [name + '_y'] + y.tolist())\n",
    "                    csv_append_col(fn, [name + '_fit'] +\n",
    "                                    out[0].best_fit.tolist())\n",
    "                    for i, model in enumerate(out[0].report['mod']):\n",
    "                        args = {key: out[0].report['mod_%d_%s' % (i, key)]\n",
    "                                for key in inspect.getargspec(model.func)[0]\n",
    "                                if key is not 'x'}\n",
    "                        csv_append_col(fn, [name + '_f%d' %i] +\n",
    "                                        model.func(x, **args).tolist())\n",
    "\n",
    "\"\"\"\n",
    "## Plot in difrent ways ######################################\n",
    "# surface #################\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('2th')\n",
    "ax.set_zlabel('counts')\n",
    "ax.set_ylabel('psi')\n",
    "#ax.invert_zaxis()\n",
    "X, Y = np.meshgrid(data.x[x2:x3], data.y[y1:y2])\n",
    "Z = data.smap[y1:y2, x2:x3]\n",
    "ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                linewidth=0, antialiased=False)\n",
    "#ax.plot_wireframe(X, Y, Z, alpha=0.3, cmap=cm.coolwarm)\n",
    "cset = ax.contour(X, Y, Z, zdir='z', offset=0, cmap=cm.coolwarm)\n",
    "cset = ax.contourf(X, Y, Z, zdir='x', offset=39, cmap=cm.coolwarm)\n",
    "cset = ax.contourf(X, Y, Z, zdir='y', offset=5, cmap=cm.coolwarm)\n",
    "plt.show()\n",
    "# make 3d line plot of small range ##################\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('2th')\n",
    "ax.set_zlabel('counts')\n",
    "ax.set_ylabel('psi')\n",
    "#ax.invert_zaxis()\n",
    "ys = data.y[y1:y2]\n",
    "for i, line in enumerate(data.smap[y1:y2, x2:x3]):\n",
    "    y = [ys[i]] * len(line)\n",
    "    ax.plot(data.x[x2:x3], y, line)\n",
    "#ax.view_init(120, 260)\n",
    "#plt.draw()\n",
    "plt.show()\n",
    "# The other way\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('2th')\n",
    "ax.set_zlabel('counts')\n",
    "ax.set_ylabel('psi')\n",
    "#ax.invert_zaxis()\n",
    "xs = data.x[x2:x3]\n",
    "for i, line in enumerate(smapT[x2:x3, y1:y2]):\n",
    "    x = [xs[i]] * len(line)\n",
    "    ax.plot(x, data.y[y1:y2], line)\n",
    "#ax.view_init(120, 260)\n",
    "#plt.draw()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "print('DONE')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
